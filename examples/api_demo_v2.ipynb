{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9892c5d",
   "metadata": {},
   "source": [
    "# `searchlite` API Embedding Model Demo Notebook v2.0 \n",
    "This notebook contains code walking through how to use `searchlite` with an embedding model accessed via API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4054af26",
   "metadata": {},
   "source": [
    "This demo notebook uses the Google Gemini API and requires the google python package. Before running this notebook, **make sure you've pip installed both searchlite and the python package of your API**. In this case, you would do:\n",
    "\n",
    "```bash \n",
    "pip install searchlite google\n",
    "```\n",
    "\n",
    "In this notebook we'll load a sample text data set with some metadata, split the dataframe into the text and its metadata, load it into `searchlite`, and perform/display a semantic search.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4240c8e",
   "metadata": {},
   "source": [
    "First, import your dependencies to load your data. For this example,             you'll only need pandas (for loading in our example data) and os (for defining the file path to our example data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb85a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7e31e",
   "metadata": {},
   "source": [
    "## Import and look at data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc7d778",
   "metadata": {},
   "source": [
    "Next, define the path to the sample data. In this case it is in the data folder.            After defining the path, use pandas to load in the csv file as a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba2edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\n",
    "   os.path.join(os.getcwd(), '../data/synthetic_data.csv'),\n",
    "   index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd5370",
   "metadata": {},
   "source": [
    "Let's take a look at our sample data below. The data consists of 15 distinct pieces             of text with corresponding id and category values. Each text topic is quite different so you can test the                 semantic search with different queries to see if the results makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa760e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a905a6",
   "metadata": {},
   "source": [
    "Before initializing the `Document` class, you need to split the dataframe into the             text you want to embed and it's corresponding metadata (shown below). You can accomplish this by simply                 isolating the text column and by using the .to_dict() method to convert the metadata columns into a                     list of dictionaries, with each entry corresponding to a row in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = sample_df[\"text\"]\n",
    "sample_metadata = sample_df[[\"id\", \"category\"]].to_dict(orient = \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f32c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_metadata[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c401714e",
   "metadata": {},
   "source": [
    "## Use searchlite to embed text and run semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e40ffc",
   "metadata": {},
   "source": [
    "Now, you can initialize our `Document` class. As shown below, both the text and metadata             are saved as attributes. Before performing search, you must generate embeddings for the texts stored within the                 `Document` instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13b56e",
   "metadata": {},
   "source": [
    "\n",
    "We'll be using the Google Gemini API for this demo. Before writing any code, **make sure you've pip installed teh appropriate libraries to access your api**.\n",
    "\n",
    "```bash\n",
    "pip install google\n",
    "```\n",
    "\n",
    "The `ApiEmbedder` instance will automatically check if your embed_func() is structured properly. \n",
    "\n",
    "To run an ApiEmbedder, you'll need to import `Document` and `ApiEmbedder` from `searchlite`.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f11721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchlite.document import Document\n",
    "from searchlite.embedders.api import ApiEmbedder   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02585a4",
   "metadata": {},
   "source": [
    "Before creating your document, you have to instantiate your `ApiEmbedder`. Unlike the other embedder classes, the `ApiEmbedder` class requires a bit more upfront work to integrate into searchlite. \n",
    "\n",
    "First, read through your API's documentation to see how to extract embeddings on a single string and on a list of strings. Then write an embedding function that takes in a string or list of strings, calls your embedding api, and returns a numpy array of embeddings. **Your embedding function MUST return a numpy array for BOTH an indivual string AND a list of strings**. \n",
    "\n",
    "The `ApiEmbedder` instance will check that your embedding function adheres to these output guidlines and will raise an error if it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66544871",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = OllamaEmbedder(model_name = 'nomic-embed-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4747b5bc",
   "metadata": {},
   "source": [
    "Now, you can initialize our `Document` class. As shown below, both the text and metadata are saved as attributes. Before performing search, you must generate embeddings for the texts stored within the `Document` instance. \n",
    "\n",
    "Be sure to assign your instantiated embedder to the embedder attribute of your document. If you don't, `searchlite` will automatically assign the `SkTFIDFEmbedder` as the embedding model for the document.\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document(texts = sample_texts, metadata = sample_metadata, embedder = embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0412cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4611fb98",
   "metadata": {},
   "source": [
    "Run the .embed() method to run scikit-learn's TFIDF Vectorizer. If you want to use a different             source for your embedding model, check out the other example notebooks to see how to initialize an embedder and pass it to your `Document`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdbb0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.embed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4442fdd4",
   "metadata": {},
   "source": [
    "After generating your text embeddings, you can run semantic search on your text corpus by using the             .query() method. Your query will be embedded into a vector and compared against your text corpus using cosine similarity.                 By default, .query() returns the top 3 matches but this can be changed by modifying the **top_k** parameter.\n",
    "As you can                     see from the cell below, .query() returns a list of dictionaries with each dictionary containing the metadata and text                         of the identified matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = doc.query(query_text = 'wireless earbuds with good battery life')\n",
    "res          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff657605",
   "metadata": {},
   "source": [
    "The `Document` class has three options to nicely display the results of your semantic search in the terminal: f-string, pprint, and tabulate.\n",
    "\n",
    "- \"f-string\" outputs a custom f-string (defined in document.py)\n",
    "\n",
    "- \"pprint\" leverages the pprint package to display a list of dictionaries of the top k results\n",
    "\n",
    "- \"tabulate\" leverages the tabulate library to display a table of the top k results.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef84d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.display_results(output_list_dict = res, style = 'f-string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1ae7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.display_results(output_list_dict = res, style = 'pprint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.display_results(output_list_dict = res, style = 'tabulate')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
